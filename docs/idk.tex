\documentclass[12pt,a4paper]{article}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\usepackage{hyperref}
\usepackage{tikz}
\usepackage{ifthen}
\usepackage{xcolor}
\hypersetup{
	colorlinks,
	linkcolor={blue!80!black},
	citecolor={red!50!black},
	urlcolor={blue!80!black}
}

\setlength{\textwidth}{16.6cm} \setlength{\textheight}{26.5cm}% Formatierung der Seite
\setlength{\topmargin}{-2.5cm} \setlength{\oddsidemargin}{-0.5cm}
\setlength{\evensidemargin}{-0.0cm}

\setlength{\parskip}{\baselineskip}
\setlength\parindent{0pt}

\newcommand{\mat}[1]{\begin{bmatrix} #1 \end{bmatrix}}
\newcommand{\jmat}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\jmatn}[3]{\frac{\partial^{#1} #2}{\partial #3^{#1}}}
\DeclareMathOperator{\re}{re}
\DeclareMathOperator{\im}{im}

% !TeX spellcheck = en_US

\begin{document}

\section{basic concepts}

\subsection{terminology \& notation}

For the purpose of this document, we'll define the Mandelbrot set as the set of points $c\in\mathbb C$ for which the sequence $(z_n)$ defined by $z_0:=0$ and $z_{n+1}:=z_n^2+c$ remains bounded. This sequence is then called the orbit of $c$.

\subsection{derivatives}

There are two sorts of derivatives that are going to particularly important later on; the first is the derivative $\frac{dz_n}{dc}$ of a point $z_n$ with respect to $c$, the second is the derivative $\frac{dz_n}{dz_1}$ of that point with respect to $z_1$, that is, the rate at which $z_n$ would change if $z_1$ was varied but $c$ stayed constant. Like $z_n$, both of these can be computed iteratively:
$$z_{n+1}=z_n^2+c$$
\begin{align*}
	\Rightarrow&&\frac{dz_{n+1}}{dc}&=2z_n\frac{dz_n}{dc}+1,&\frac{dz_{n+1}}{dz_1}&=2z_n\frac{dz_n}{dz_1}\\
	\Rightarrow&&\frac{d^2z_{n+1}}{dc^2}&=2z_n\frac{d^2z_n}{dc^2}+2\left(\frac{dz_n}{dc}\right)^2,&\frac{d^2z_{n+1}}{dz_1^2}&=2z_n\frac{d^2z_n}{dz_1^2}+2\left(\frac{dz_n}{dz_1}\right)^2\\
	&&&\;...&&\;...\\
	&&\frac{d^kz_{n+1}}{dc^k}&=\sum_{i=0}^k\binom ki\frac{d^iz_n}{dc^i}\cdot\frac{d^{k-i}z_n}{dc^{k-i}},&\frac{d^kz_{n+1}}{dz_1^k}&=\sum_{i=0}^k\binom ki\frac{d^iz_n}{dz_1^i}\cdot\frac{d^{k-i}z_n}{dz_1^{k-i}}.
\end{align*}

As we can see, both higher derivatives can be elegantly expressed by the same formula; the only difference here is that the first derivative $\frac{dz_n}{dc}$ contains an extra $+1$ compared to $\frac{dz_n}{dz_1}$.

\subsection{polynomials}


Instead of looking at the orbits of individual points, one can also look at the iterations as a sequence of polynomials, recursively defined as $p_1:=c$ and $p_{n+1}:=p_n^2+c$. Those are what we'll here call the Mandelbrot polynomials; they are all monic, of degree $\deg(p_n)=2^n$, divisible by $c$ and related to our previously defined concepts by $p_n(c)=z_n$ and $p_n'(c)=\frac{dz_n}{dc}$.

The reason those are interesting to us is that the zeroes of those polynomials $p_n$ are exactly the points whose orbits are periodic; since $z_{n+1}$ only depends on $z_n$ and $c$, $z_n=0=z_0$ inductively implies $z_{n+m}=z_m$ for all $m$. These periodic points will be of particular importance later on for finding minibrots, making methods for finding zeroes of these polynomials immensely important.

For now though, the important bit here is that zeroes in the polynomials occur periodically; so for example, every zero of $p_3$ is also a zero of $p_6$, $p_9$, $p_{12}$ and so on. Since this is true for all zeroes, $p_6$ as a whole must be divisible by $p_3$; and in general, $p_k\mid p_n$ must for hold for all $k\mid n$.

This allows us to recursively define what I'll here call the refined Mandelbrot polynomials $q_n$: $$q_1:=p_1,\;\;\;q_n:=\frac{p_n}{\prod_{n\neq k\mid n}q_k}.$$
Each of those polynomials $q_n$ contains precisely those points as zeroes which are zeroes of $p_n$ but not any of the previous Mandelbrot polynomials; this is accomplished by dividing each $p_n$ by all $q_k$ for which $k$ is a proper divisor of $n$, and whose zeroes are thus also zeroes of $p_n$. For example, the first few such polynomials would be:
\begin{align*}
	q_1&=p_1=c,\\
	q_2&=\frac{p_2}{p_1}=c+1,\\
	q_3&=\frac{p_3}{p_1}=c^3+2c^2+c+1,\\
	q_4&=\frac{p_4}{\frac{p_2}{p_1}p_1}=c^6+3c^5+3c^4+3c^3+2c^2+1,\\
	q_5&=\frac{p_5}{p_1}=c^{15}+8c^{14}+...+2c^2+c+1,\\
	q_6&=\frac{p_6}{\frac{p_3}{p_1}\frac{p_2}{p_1}p_1}=c^{27}+13c^{26}+...+c^2-c+1,\\
	&\;...
\end{align*}
Two things become apparent quite quickly here; for one, working with those polynomials in coefficient representations quickly becomes impractical because of their large number of coefficients; and secondly, quite a lot of the polynomial divisions cancel out, leaving only relatively compact algebraic representations such as $q_4=\frac{p_4}{p_2}$ and $q_6=\frac{p_6p_1}{p_3p_2}$ behind. In fact, if we define a signum $\sigma(n)$ for each number based on its prime decomposition like this: $$\sigma(n):=\begin{cases}
	+1&\textrm{if $n$ has an even number of prime factors and none of them appear twice},\\
	-1&\textrm{if $n$ has an odd number of prime factors and none of them appear twice},\\
	0&\textrm{otherwise},
\end{cases}$$
then exactly those $p_k$ with $\sigma(\frac nk)=+1$ end up in the numerator of $q_n$ and those with $\sigma(\frac nk)=-1$ in the denominator, while those with $\sigma(\frac nk)=0$ cancel out completely.\footnote{this can be proven relatively easily by canceling out the terms $q_k$ inductively, starting at the largest ones, and showing that this property holds for them; however, since this part is already kind of long, I won't go over the proof in detail here.} With this in mind, we can now compute $q_n$ way more easily like this: $$q_n=\prod_{k\mid n}p_k^{\sigma(\frac nk)}.$$

Together with the fact that we can enumerate the values $p_1(c)$ to $p_n(c)$ for a given $c$ in linear time by iterating $z\mapsto z^2+c$, this also solves our other problem and enables us to evaluate these $q_n$ efficiently; we can just compute $p_1(c)$ to $p_n(c)$ in order, for all $k$ which divide $n$ compute $\sigma(\frac nk)$, and then multiply or divide our end result by $p_k(c)$ accordingly. This way we can compute $q_n(c)$ and similarly all of its derivatives in almost\footnote{linear time assuming $\sigma(\frac nk)$ can be computed in constant time. this of course isn't actually true, but should be pretty close; the worst case for computing $\sigma(n)$ should be at most $O(\sqrt n)$, and only occur when $n$ is prime or has very large prime factors.} linear time, without having to deal with the exponentially growing number of coefficients.
%{
	%\makeatletter
	%\newcommand\expandq[1]{
		%\ifnum#1=1 p_1\else\frac{p_{#1}}{
			%{
				%\count@=\numexpr#1-1\relax
				%\loop
				%\ifnum\numexpr#1/\count@*\count@=#1\relax{
					%\expandafter\expandq\expandafter{\the\count@}
					%\ifnum\count@>1\cdot\fi
				%}\fi
				%\advance\count@-1
				%\ifnum\count@>0
				%\repeat
			%}
		%}\fi
	%}
	%\makeatother
	%$$\expandq{12}$$
	%$$\expandq{105}$$
%}

\section{periodic points}

As we've already seen, the zeroes of these Mandelbrot polynomials are so-called periodic points; they end up exactly at zero after $n$ iterations, making their orbit repeat from that point on.

Together with our previously shown formula for the derivative $\frac{dz_m}{dc}$, this also implies that this derivative repeats itself every $n$ iterations too.\footnote{This is only true for the first derivative though; all higher derivatives are only preperiodic, not periodic. The $k$-th derivative generally only starts repeating itself after $kn$ iterations, yet still with period $n$, meaning the first $(k-1)n$ values never occur in the sequence again.} This shows that while the points around $z$ are not strictly $n$-periodic themselves (otherwise they would've been zeroes of $p_n$ too), they show a very similar behavior; more specifically, they converge against a periodic cycle of length $n$. Because of this, these periodic points are always surrounded by compact areas fully belonging to the mandelbrot set, such as disks, cardioids and other similar but slightly imperfect shapes.

Because of this, finding periodic points is immensely useful for a number of reasons; for one, they always indicate the presence of a minibrot cardioid or disk around them, meaning they can be used to automatically find and zoom towards the nearest minibrot. If the type and size of the cardioid or disk is known, they can also be used to clip parts of that disk, so these typically expensive to compute points can be discarded as inside the mandelbrot set in a matter of milliseconds.

Besides that, knowing the period of a specific minibrot or disk can be useful as well; it can be used to estimate the iteration count required to render a reasonably detailed image of that minibrot, as each iteration of that minibrot or its julia sets requires following along one cycle of that minibrot's main cardioid's orbit, taking $n$ actual iterations to complete.

Finally, being able to automatically analyze the location, period and orientation of minibrots may eventually enable us to build an algorithm that can automatically skip iterating through the full cycle and just compute iterations on the minibrot directly; this would allow rendering nested minibrots and julia sets in $O(log(n))$-complexity.

\subsection{computation}

Finding these points is also relatively simple; since they are precisely the zeroes of the mandelbrot polynomials $p_n$, Newton's method can be used to find zeroes near an initial estimate for a given $n$. Simply looping through all $n$ up to a certain maximum will yield all nearby cyclic points with a period in that range.

One slight pitfall here is that since the $n$-th Mandelbrot polynomial $p_n$ always also contains all the zeroes from all $p_k$ for which $k$ divides $n$, running Newton's method on $p_n$ may often return points whose period is not actually $n$ but a proper divisor of it. This is undesirable for multiple reasons; for one, many of the methods we'll describe here require us to know the period precisely and will produce wrong results of fed with a multiple of that period instead. This alone can of course simply be fixed by checking if the point really has the right period before proceeding, however, that still leaves us with a second problem: those redundant zeroes take up space in the Newton fractal of $p_n$, effectively shrinking the basins of attraction of the zeroes actually introduced in that iteration. Or, in other words: searching for points with period $n$ and $2n$ may return the same point point of period $n$ or smaller twice, instead of one $n$-periodic and one $2n$-periodic point, even when a point with a period $2n$ is relatively near.

This can of course be fixed by dividing out all zeroes from earlier polynomials; either by dividing them all out exactly once, as we already did with $q_n$, or by dividing $p_n$ by $p_k$ for all proper divisors $k$ of $n$ without correcting for multiplicity, creating poles where some of the zeroes used to be.\footnote{The latter has also previously been done by claude for example - see \url{https://mathr.co.uk/blog/2018-11-17_newtons_method_for_periodic_points.html}.}

[TODO: more about poles, when they are desirable and some example Newton fractals here]

%For any one of these three methods, a simple approach to find periodic points close to a given $c$ would then be to compute $z_n$ and $\frac{dz_n}{dc}$ for each iteration $n$ and each time simply try if Newton's method converges; however, as computing the values and derivatives of other points as required by Newton's method has linear complexity regarding iteration count, doing this for each iteration has a complexity of $O(n^2)$, making it very slow for high iteration counts.

%One way to speed this up is therefore to perform some simple test to see if Newtons method could converge before actually performing it; another is to improve the initial estimate, so that Newton's method converges quicker when you do actually perform it. One simple way to do the latter is to use a quadratic approximation instead of a linear one and compute the first estimate based on that using the quadratic formula:
%$$x_n \approx z_n+(x_0-z_0)\frac{dz_n}{dz_0}+\frac{1}{2}(x_0-z_0)^2\frac{d^2z_n}{dz_0^2}.$$
%$$x_0' = z_0+\frac{-\frac{dz_n}{dz_0}\pm\sqrt{(\frac{dz_n}{dz_0})^2-2\frac{d^2z_n}{dz_0^2}z_n}}{\frac{d^2z_n}{dz_0^2}}.$$
%Out of the two roots produced by this, one can then simply choose the one that is closer to the base point to get an already slightly better first estimate. It might be possible to get an even better estimate by including even more higher derivatives in the polynomial approximation and using Newton's method on that first; however, I haven't tried that yet so I'm not sure if it is actually faster.

%Regardless of which method is used to compute this estimate, as long as the derivative $\frac{dx_0'}{dz_0}$ of that estimate with respect to $z_0$ can also be computed, a simple test to decide whether to use Newton's method this iteration or not would be to test if the absolute value of that derivative is less than one (or some other constant, for that matter); that way, estimates which are relatively unstable and dependent on $z_0$ can be quickly discarded. As an example, for the quadratic estimate described above this derivative could be computed like this:
%\begin{align*}
	%\frac{dx_0'}{dz_0} &= \frac{d\left(z_0+\frac{(x_0'-z_0)\cdot\frac{d^2z_n}{dz_0^2}}{\frac{d^2z_n}{dz_0^2}}\right)}{dz_0}\\
	%&= 1+\frac{\frac{d\left((x_0'-z_0)\cdot\frac{d^2z_n}{dz_0^2}\right)}{dz_0}\cdot\frac{d^2z_n}{dz_0^2}-((x_0'-z_0)\cdot\frac{d^2z_n}{dz_0^2})\cdot\frac{d^3z_n}{dz_0^3}}{(\frac{d^2z_n}{dz_0^2})^2}\\
	%&=1+\frac{\frac{d\left(-\frac{dz_n}{dz_0}\pm\sqrt{(\frac{dz_n}{dz_0})^2-2\frac{d^2z_n}{dz_0^2}z_n}\right)}{dz_0}-(x_0'-z_0)\cdot\frac{d^3z_n}{dz_0^3}}{\frac{d^2z_n}{dz_0^2}}\\
	%&=1+\frac{-\frac{d^2z_n}{dz_0^2}\pm\left(\frac{\frac{d((\frac{dz_n}{dz_0})^2-2\frac{d^2z_n}{dz_0^2}z_n)}{dz_0}}{2\sqrt{(\frac{dz_n}{dz_0})^2-2\frac{d^2z_n}{dz_0^2}z_n}}\right)-(x_0'-z_0)\cdot\frac{d^3z_n}{dz_0^3}}{\frac{d^2z_n}{dz_0^2}}\\
	%&=\frac{\pm\frac{2\cdot\frac{dz_n}{dz_0}\cdot\frac{d^2z_n}{dz_0^2}-2(\frac{d^3z_n}{dz_0^3}z_n+\frac{d^2z_n}{dz_0^2}\cdot\frac{dz_n}{dz_0})}{2\sqrt{(\frac{dz_n}{dz_0})^2-2\frac{d^2z_n}{dz_0^2}z_n}}-(x_0'-z_0)\cdot\frac{d^3z_n}{dz_0^3}}{\frac{d^2z_n}{dz_0^2}}\\
	%&=\frac{\frac{-\frac{d^3z_n}{dz_0^3}z_n}{\pm\sqrt{(\frac{dz_n}{dz_0})^2-2\frac{d^2z_n}{dz_0^2}z_n}}-(x_0'-z_0)\cdot\frac{d^3z_n}{dz_0^3}}{\frac{d^2z_n}{dz_0^2}}\\
	%&=\frac{\frac{-\frac{d^3z_n}{dz_0^3}z_n}{(x_0'-z_0)\cdot\frac{d^2z_n}{dz_0^2}+\frac{dz_n}{dz_0}}-(x_0'-z_0)\cdot\frac{d^3z_n}{dz_0^3}}{\frac{d^2z_n}{dz_0^2}}\\
	%%&\;...\\
	%&=-\frac{\frac{d^3z_n}{dz_0^3}}{\frac{d^2z_n}{dz_0^2}}\cdot\left(\frac{z_n}{(x_0'-z_0)\cdot\frac{d^2z_n}{dz_0^2}+\frac{dz_n}{dz_0}}+(x_0'-z_0)\right).
%\end{align*}
%sCalculating this, $x_0'$ and all the derivatives necessary for that for every single iteration on the base point $z_0$ just to see if Newton's method could be used is obviously kind of slow itself; however, the crucial part here is that this doesn't require any derivative samples from other points each iteration, and as such runs with nearly linear complexity in regards to the iteration count $n$ (though it still requires these samples to use Newton's method for iterations where it could converge according to the test - if you factor that in, the complexity is probably something like $O(n\log(n))$).

\subsection{finding minibrots}

Finding points with cyclic orbits is all well and good, but to really take advantage of that we also need to be able to locate the minibrots around them; that is, detect whether the point belongs to a cardioid or disk, and what the orientation and size of that cardioid or disk is.

To do this, let's assume we already have a perfectly $n$-periodic starting point $c$, meaning that $z_n$ is exactly zero and is the first element in the sequence to do so. The $n$th iteration of points $c'$ close to $c$ can then as usual be approximated as $x_n\approx z_n+(c'-c)\frac{dz_n}{dc}$; but since $z_n$ is $0$, this then simplifies down to $x_n\approx(c'-c)\frac{dz_n}{dc}$. Let's call this value $d_1$. The next iteration can then be approximated as $x_{n+1}\approx c'+d_1^2=x_1+d_1^2$; the iteration after that as
\begin{align*}
	x_{n+2} &\approx (x_1+d_1^2)^2+x_1\\
	&=x_1^2+2x_1d_1^2+d_1^4+x_1\\
	&=x_2+2x_1d_1^2+d_1^4.
\end{align*}
However, as $d_1^2$ is already very, very close to zero, the term $d_1^4$ and any terms multiplied by it can be ignored as they are basically negligible in comparison; also, $x_1d_1^2$ can be replaced with $z_1d_1^2$ for similar reasons:
\begin{align*}
	x_{n+2} &\approx x_2+2z_1d_1^2\\
	x_{n+3} &\approx (x_2+2z_1d_1^2)^2+x_1\\
	&=x_2^2+4z_1x_2d_1^2+4z_1^2d_1^4+x_1\\
	&\approx x_3+4z_1z_2d_1^2\\
	x_{n+4} &\approx x_4+8z_1z_2z_3d_1^2\\
	...
\end{align*}
This pattern continues until we hit the next multiple of $n$; let's call this value $d_2$:
\begin{align*}
	x_{2n} &\approx x_n+2^{n-1}(z_1z_2...z_{n-1})d_1^2\\
	&\approx d_1+2^{n-1}(z_1z_2...z_{n-1})d_1^2\\
	&=d_1+\frac{dz_n}{dz_1}d_1^2\\
	&=:d_2.
\end{align*}
Now it should already become apparent why these minibrots even exist; $x_{2n+1}$ will then be $x_1+d_2^2$, $x_{3n}$ will be $d_1+\frac{dz_n}{dz_1}d_2^2$ and so on; generally, the values $x_{kn}$ will closely follow the sequence $(d_k)$ defined by $d_1:=(c'-c)\frac{dz_n}{dc}$ and $d_{k+1}=\frac{dz_n}{dz_1}d_k^2+d_1$ as long as it stays small enough, completing one iteration of $d$ every $n$ iterations of $x$.

To get rid of the factor $\frac{dz_n}{dz_1}$ and turn this into an equation of the form $d_{k+1}'=d_k'^2+d_1'$, we can just multiply both sides of the equation with it:
$$\frac{dz_n}{dz_1}d_{k+1}=\left(\frac{dz_n}{dz_1}d_k\right)^2+\frac{dz_n}{dz_1}d_1.$$
It is therefore the sequence $(d_k')$ defined by $d_k':=\frac{dz_n}{dz_1}d_k$ that actually iterates just like the mandelbrot set, and the term $\frac{dz_n}{dz_1}d_1$ or $\frac{dz_n}{dz_1}\frac{dz_n}{dc}(c'-c)$ that acts as the starting value for it; as such, a number $s$ indicating the scale and orientation of the minibrot set can be computed as $$s=\frac{1}{\frac{dz_n}{dz_1}\frac{dz_n}{dc}}.$$

The center of the main disk of the minibrot is then approximately $c-1\cdot s$ instead of the usual $-1$, the tip of the needle approximately $c-2\cdot s$ and so on.

\subsection{minibrot formulas}

[TODO]

\subsection{skipping iterations - very WIP indeed}

%While the sequence above is probably the simplest one to see why minibrots exist, it is not the only example of a subsequence that can itself be approximated using a simple iterative formula. To see how these work in general, let's again consider an $n$-cyclic starting point $z_0$ and a nearby starting point $x_0$, as well as the sequence $d_i:=x_i-z_i$:

[just image some explanatory text here for now, gotta add that later]. Let $z_0$ again be a point with an $n$-cyclic orbit, $x_0$ a point very close to that, and $d_i:=x_i-z_i$ for all $i\in\mathbb{N}_0$:

\begin{align*}
	d_{i+1}&=x_{i+1}-z_{i+1}\\
	&=x_i^2+x_0-z_i^2-z_0\\
	&=(x_i+z_i)(x_i-z_i)+d_0\\
	&=d_i^2+2z_id_i+d_0.
\end{align*}
As long as $d_i$ is way smaller than $z_i$, the term $d_i^2$ is also way smaller than $2z_id_i$; in that case, it can just be ignored, so $d_{i+1}$ can be approximated as $2z_id_i+d_0$. Let's use this to approximate the points following $d_{kn}$ for an $k\in\mathbb{N}$:
\begin{align*}
	d_{kn+1}&\approx 2z_{kn}d_{kn}+d_0.
\end{align*}
Since the orbit of $z_0$ is $n$-cyclic, $z_{kn}$ must be equal to $z_0$; likewise, $z_{kn+1}$ would be equal to $z_1$ and so on:
\begin{align*}
	d_{kn+1}&\approx 2z_0d_{kn}+d_0\\
	d_{kn+2}&\approx 2z_{kn+1}d_{kn+1}+d_0\\
	&\approx 2z_1(2z_0d_{kn}+d_0)+d_0\\
	&\approx 4z_0z_1d_{kn}+(2z_1+1)d_0
	%&=4z_0z_1d_{kn}+(2z_1(1+2z_0-2z_0)+1)d_0\\
	%&=4z_0z_1d_{kn}+(2z_1(2z_0+1)+1-4z_0z_1)d_0\\
	%d_{kn+3}&\approx 2z_{kn+2}d_{kn+2}+d_0\\
	%&\approx 2z_2(2z_0z_1d_{kn}+(2z_1+1)d_0)+d_0\\
	%&\approx 2z_0z_1z_2d_{kn}+(2z_2(2z_1+1)+1)d_0\\
	%...
\end{align*}
If the last term here already looks kind of familiar, that's because it is similar to $2z_1(2z_0+1)+1$ or $2z_1\frac{dz_1}{dz_0}$, which we've previously shown to be $\frac{dz_2}{dz_0}$; as such, we can simplify that term by writing it in terms of that:
\begin{align*}
d_{kn+2}&\approx 4z_0z_1d_{kn}+(2z_1+1)d_0\\
&=4z_0z_1d_{kn}+(2z_1(1+2z_0-2z_0)+1)d_0\\
&=4z_0z_1d_{kn}+(2z_1(2z_0+1)+1-4z_0z_1)d_0\\
&=4z_0z_1d_{kn}+(\frac{dz_2}{dz_0}-4z_0z_1)d_0\\
d_{kn+3}&\approx 2z_{kn+2}d_{kn+2}+d_0\\
&\approx 2z_2(4z_0z_1d_{kn}+(\frac{dz_2}{dz_0}-4z_0z_1)d_0)+d_0\\
&=8z_0z_1z_2d_{kn}+(2z_2\frac{dz_2}{dz_0}-8z_0z_1z_2+1)d_0\\
&=8z_0z_1z_2d_{kn}+(\frac{dz_3}{dz_0}-8z_0z_1z_2)d_0\\
...\\
d_{(k+1)n-1}&\approx 2^{n-1}z_0z_1...z_{n-2}d_{kn}+(\frac{dz_{n-1}}{dz_0}-2^{n-1}z_0z_1...z_{n-2})d_0.
\end{align*}
At this point, the pattern breaks; since $z_{(k+1)n-1}$ must be equal to zero, our assumption that $d_i$ is smaller than $z_i$ is no longer true, so our previous approximation $2z_id_i+d_0$ is no longer that accurate. Instead, the term $2z_id_i$ is now equal to zero:
\begin{align*}
	d_{(k+1)n}&=x_{(k+1)n}-z_{(k+1)n}\\
	&=x_{(k+1)n-1}^2+x_0-z_{(k+1)n-1}^2-z_0\\
	&=(z_{(k+1)n-1}+d_{(k+1)n-1})^2+d_0\\
	&=d_{(k+1)n-1}^2+d_0\\
	&\approx (2^{n-1}z_0z_1...z_{n-2}d_{kn}+(\frac{dz_{n-1}}{dz_0}-2^{n-1}z_0z_1...z_{n-2})d_0)^2+d_0.
\end{align*}
As before, the term $2^{n-1}z_0z_1...z_{n-2}$ appears in this equation, this time even twice; let's call it $a$ for now to clean things up:
$$d_{(k+1)n}\approx (ad_{kn}+(\frac{dz_{n-1}}{dz_0}-a)d_0)^2+d_0.$$

With this, we have again found an approximation that computes $n$ iterations at once. The sequence $(d_{kn})_{k\in\mathbb{N}_0}$ produced by this is essentially the same as an orbit in the mandelbrot set, just scaled, rotated and translated; to show this, let's take a look at the sequence $\Delta_k:=a^2d_{kn}+a(\frac{dz_{n-1}}{dz_0}-a)d_0$:
\begin{align*}
	\Delta_{k+1}&=a^2d_{(k+1)n}+a(\frac{dz_{n-1}}{dz_0}-a)d_0\\
	&\approx a^2((ad_{kn}+(\frac{dz_{n-1}}{dz_0}-a)d_0)^2+d_0)+a(\frac{dz_{n-1}}{dz_0}-a)d_0\\
	&= (a^2d_{kn}+a(\frac{dz_{n-1}}{dz_0}-a)d_0)^2+a^2d_0+a(\frac{dz_{n-1}}{dz_0}-a)d_0\\
	&= \Delta_k^2+\Delta_0.
\end{align*}
In fact, all subsequences of the form $(d_{kn+i})k\in\mathbb{N}_0$ for $0\leq i\leq n-1$ can be approximate as scaled, rotated and translated versions of this sequence $\Delta$; this can be shown by rearranging and then substituting in our previously shown formula $d_{kn+i}\approx 2^iz_0z_1...z_{i-1}d_{kn}+(\frac{dz_i}{dz_0}-2^iz_0z_1...z_{i-1})d_0$:
\begin{align*}
	d_{kn+i}&\approx 2^iz_0z_1...z_{i-1}d_{kn}+(\frac{dz_i}{dz_0}-2^iz_0z_1...z_{i-1})d_0\\
	\Rightarrow d_{kn}&\approx\frac{d_{kn+i}-(\frac{dz_i}{dz_0}-2^iz_0z_1...z_{i-1})d_0}{2^iz_0z_1...z_{i-1}}
	\\\\
	\Delta_k&=a^2d_{kn}+a(d\frac{z_{n-1}}{dz_0}-a)d_0\\
	&\approx a^2(\frac{d_{kn+i}-(\frac{dz_i}{dz_0}-2^iz_0z_1...z_{i-1})d_0}{2^iz_0z_1...z_{i-1}})+a(\frac{dz_{n-1}}{dz_0}-a)d_0\\
	%&=a^2\frac{d_{kn+i}}{2^iz_0z_1...z_{i-1}}-a^2\frac{\frac{dz_i}{dz_0}d_0}{2^iz_0z_1...z_{i-1}}+a^2d_0+a(\frac{dz_{n-1}}{dz_0}-a)d_0\\
	&=a^2\frac{d_{kn+i}}{2^iz_0z_1...z_{i-1}}-a^2\frac{\frac{dz_i}{dz_0}d_0}{2^iz_0z_1...z_{i-1}}+a\frac{dz_{n-1}}{dz_0}d_0\\
	&=a(2^{n-i-1}z_iz_{i+1}...z_{n-2})d_{kn+i}+a(\frac{dz_{n-1}}{dz_0}-(2^{n-i-1}z_iz_{i+1}...z_{n-2})\frac{dz_i}{dz_0})d_0.
\end{align*}
For $i=0$, this produces exactly the equation we used to define $\Delta_k$; for $i=n-1$, this produces the equation $\Delta_k\approx ad_{(k+1)n-1}$, which as we've shown in the previous section, indeed behaves like a normal orbit in the mandelbrot set too.

[I'll add more text here later, for now I'm still experimenting how this can best be implemented in the form of an algorithm to skip iterations efficiently. Just wanted to write down these equations here for now, before I forget them again.]

\section{Generalizing for other fractals - WIP}

Applying these same methods to other popular fractals such as the mandelbar set (also commonly referred to as tricorn) or the burning ship fractal is slightly complicated by the fact that these are based on non-conformal mappings (which can even be seen visually; they contain heavily skewed parts), meaning that their derivative can't simply be expressed as a single complex number.

Instead, we'll have to treat the real and imaginary component as separate real numbers, here referred to as $\re(z)$ and $\im(z)$, and use a matrix of partial derivatives:
$$\frac{\partial z_n}{\partial z_0} = \mat{\frac{d\re(z_n)}{d\re(z_0)}&\frac{d\re(z_n)}{d\im(z_0)}\\\frac{d\im(z_n)}{d\re(z_0)}&\frac{d\im(z_n)}{d\im(z_0)}}.$$
Similar a normal derivative, this Jacobian matrix tells us how the region of points close to $z_0$ is transformed relative to $z$; however, while a normal derivative can only encode the scale and rotation part of this transformation, the Jacobian encodes precisely how much both components of $z_n$ change with respect to both components of $z_0$.

In the case of the mandelbar set for example, this is needed because its formula involves the complex conjugate $\bar{z}$, which flips the sign of the imaginary but not the real component of $z$; similarly, the burning ship fractal makes use of the component-wise $abs$ function, which too flips regions in the second and fourth quadrant in such a way that a single scale and rotation value is no longer enough to fully encode the resulting transformation. Hence, the Jacobian matrix is needed.

Even worse though, there are now 8 second-order partial derivatives required to accurately describe the change rate of the Jacobian - and 16 third-order partial derivatives, 32 fourth-order ones and so on.
While these can all still be iteratively computed, doing so quite quickly becomes infeasible as the number of required operations per iteration grows exponentially. As such, we are mostly limited to working with the first- and second-order partial derivatives for these fractals.

Now, before we start actually doing anything with those, a few other quick definitions: I'll from here on use $M(z)$ to refer to the matrix $\mat{re(z)&-im(z)\\im(z)&re(z)}$; that way, multiplying $z$ with another number $a$ now has the effect of multiplying the Jacobian $\jmat{z}{z_0}$ with $M(a)$, similar to how it previously would have had the effect of multiplying the derivative by $a$. Also, I'll from here on use the concept of complex numbers and vectors interchangeably; for example, the product $\mat{a&b\\c&d}\cdot z$ would then be equal to $a\re(z)+b\im(z)+(c\re(z)+d\im(z))i$. I know this is probably a terrible way to write this down, but I sadly couldn't find a better one, so please excuse the mess of equations you're about to see.

\subsection{Finding cyclic points}

With that being said, let's now start by examining how we can use this to apply our previous equations to the mandelbar set. We'll begin with the first derivative - or now, Jacobian - of the sequence once again:
\begin{align*}
	z_{n+1} &= \bar{z}_n^2+z_0\\
	\jmat{z_{n+1}}{z_0} &= \jmat{(\bar{z}_n^2+z_0)}{z_0}\\
	&= \jmat{\bar{z}_n^2}{z_0}+\jmat{z_0}{z_0}\\
	&= \mat{1&0\\0&-1}\cdot\jmat{z_n^2}{z_0}+\mat{1&0\\0&1}\\
	&= \mat{2&0\\0&-2}\cdot M(z_n)\cdot\jmat{z_n}{z_0}+\mat{1&0\\0&1}.
\end{align*}
While similar equations could also be found for the second-order partial derivatives, there's at least as far as I know no simple way of representing those using a matrix; so, we'll just ignore those for now and see what we can do using the Jacobian alone.

Similar to what we did with the derivative before, we can use the Jacobian to get a linear approximation of $x_n$ for points $x_0$ close to the point the Jacobian was computed for:
$$x_n \approx z_n+\jmat{z_n}{z_0}(x_0-z_0).$$
Based on that, we can again compute the root of this approximation and use that as a new base point; repeating this a number of times, we can again find a $n+1$-cyclic point using Newton's method:
$$x_0' = z_0-\left(\jmat{z_n}{z_0}\right)^{-1}z_n.$$
The derivative $\frac{dx_0'}{z_0}$ can then also be computed based on the second-order partial derivatives, so we can use that as a quick check whether Newton's Method might converge or not; however, this also limits us to the linear approximation, as calculating this derivative for an estimate that's based on a quadratic approximation as we did before would require third-order partial derivatives, which are due to their sheer number expensive to compute.

\subsection{Finding Minibrots}

As before, we of course also want to know what structure any given cyclic point belongs to - whether it is a disk, ellipse, minibrot or another miniature fractal, and what the scale and orientation of that structure is.

Again, we start using a perfectly $n$-cyclic starting point $z_0$ and some other point $x_0$ around it; the $n-1$th iteration of this point can then again be approximated as $x_{n-1} \approx z_{n-1}+\jmat{z_{n-1}}{z_0}(x_0-z_0)$, which simplifies down to just $x_{n-1} \approx \jmat{z_{n-1}}{z_0}(x_0-z_0)$ since $z_{n-1}$ is exactly zero. Let's call this value $d_0$ again, as we did before.

The next iteration can then be approximated as $x_n\approx x_0+\bar{d_0^2}$; the iteration after that as
\begin{align*}
	x_{n+1} &\approx (\overline{x_0+\overline{d_0^2}})^2+x_0\\
	&\approx \overline{x_0^2}+2\overline{x}_0d_0^2+d_0^4+x_0\\
	&\approx x_1+2\overline{z}_0d_0^2+2(\overline{x}_0-\overline{z}_0)d_0^2+d_0^4.
\end{align*}
And again, the terms $2(\overline{x}_0-\overline{z}_0)d_0^2$ and $d_0^4$ can be simply discarded as they are basically negligible in comparison to the other terms:
\begin{align*}
	x_{n+1} &\approx x_1+2\overline{z}_0d_0^2\\
	x_{n+2} &\approx (\overline{x_1+2\overline{z}_0d_0^2})^2+x_0\\
	&\approx \overline{x_1^2}+4z_0\overline{x}_1\overline{d_0^2}+4z_0\overline{d_0^4}+x_0\\
	&\approx x_2+4z_0\overline{z}_1\overline{d_0^2}\\
	x_{n+3} &\approx x_3+8\overline{z}_0z_1\overline{z}_2d_0^2\\
	...\\
	x_{2n-1} &\approx \begin{cases}
		x_{n-1}+2^{n-1}\overline{z}_0z_1...\overline{z}_{n-2}d_0^2 & \text{for } n \equiv 0 \mod 2\\
		x_{n-1}+2^{n-1}z_0\overline{z}_1...\overline{z}_{n-2}\overline{d_0^2} & \text{for } n \equiv 1 \mod 2
	\end{cases}
\end{align*}
By substituting $d_1$ for $x_{2n-1}$ and repeating this, we can again find a general equation for the sequence of points $d_k$ approximating $x_{(k+1)n-1}$:
$$d_{k+1} = \begin{cases}
2^{n-1}\overline{z}_0z_1...\overline{z}_{n-2}d_k^2+d_0 & \text{for } n \equiv 0 \mod 2\\
2^{n-1}z_0\overline{z}_1...\overline{z}_{n-2}\overline{d_k^2}+d_0 & \text{for } n \equiv 1 \mod 2
\end{cases}$$
Notice how the sequence behaves differently this time depending on whether the cycle length $n$ is even or odd; if it is even, all of the conjugates applied to the previous element of the sequence cancel each other out, if it is odd they don't. This is the reason that the mandelbar set contains both smaller copies of itself and of the mandelbrot set; depending on the cycle length, the points close to the cyclic point undergo different transformations that can't even be made equivalent through a shift of reference (for example by multiplying by a certain constant, as we did earlier with the mandelbrot set); as such, they produce different miniature fractals. This is generally one of the biggest challenges when trying to apply these methods to other fractals; most of them contain not just one or two different kinds of miniature fractals, but a whole spectrum of them plus an often infinite number of hard to generalize edge-cases.

In case of the mandelbar set again, the first case just boils down to the classic mandelbrot set equation:
\begin{align*}
	d_{k+1} &= 2^{n-1}\overline{z}_0z_1...\overline{z}_{n-2}d_k^2+d_0\\
	2^{n-1}\overline{z}_0z_1...\overline{z}_{n-2}d_{k+1} &= (2^{n-1}\overline{z}_0z_1...\overline{z}_{n-2}d_k)^2+2^{n-1}\overline{z}_0z_1...\overline{z}_{n-2}d_0.
\end{align*}
Similar to what we had before, it is the sequence of values $2^{n-1}\overline{z}_0z_1...\overline{z}_{n-2}\cdot d_k$ that actually iterates based on the same formula as the mandelbrot set, and the value $2^{n-1}\overline{z}_0z_1...\overline{z}_{n-2}d_0$ that acts as the starting value for; thus, we can again compute the scale and orientation of that minibrot or disk as the ratio between this value and $x_0$:
\begin{align*}
	a &= \jmat{x_0}{(2^{n-1}\overline{z}_0z_1...\overline{z}_{n-2}d_0)}\\
	&= \left(\jmat{(2^{n-1}\overline{z}_0z_1...\overline{z}_{n-2}d_0)}{x_0}\right)^{-1}\\
	&= \left(M(2^{n-1}\overline{z}_0z_1...\overline{z}_{n-2})\jmat{x_{n-1}}{x_0}\right)^{-1}.
\end{align*}
One important difference to the original equation though is that this value $a$ is now a $2\times2$ matrix instead of a real number; this comes from the fact that most (if not all) disks and minibrots in the mandelbar set are skewed to at least some degree, therefore requiring an entire matrix to fully encode their scale, rotation and stretch factor and direction.

The second case though is already somewhat more complicated. To show that it is equivalent to the mandelbar set equation for some sequence $b\cdot d_k$, we need to again turn in into an equation of the form $bd_k=(\overline{bd_k})^2+bd_0$; however this time, it's not possible to do that by just multiplying both sides of the equation with the coefficient $c=2^{n-1}z_0\overline{z}_1...\overline{z}_{n-2}$. Instead, we need to actually solve those two forms of the equation for $b$:
\begin{align*}
	d_{k+1} &= c\cdot\overline{d_k^2}+d_0\\
	bd_{k+1} &= bc\cdot\overline{d_k^2}+bd_0\\
	bc &= \overline{b^2}\\
	c &= \frac{\overline{b^2}}{b} = \frac{\overline{b^3}}{\left|b^2\right|}\\
	b &= \overline{\sqrt[3]{c}}\cdot\left|c\right|^\frac{2}{3}
\end{align*}
Of course the cube root is not uniquely defined for complex numbers, but that doesn't matter for our use case here; any one of the three roots of the polynomial $x^3=c$ will work, since the mandelbar set is rotationally symmetric by exactly 120 degrees.

After choosing one of these possible values for $b$, we can again compute the matrix $a$ as the Jacobian matrix $\jmat{x_0}{(bd_0)}$:
\begin{align*}
	a &= \jmat{x_0}{(bd_0)}\\
	&= \left(\jmat{(bd_0)}{x_0}\right)^{-1}\\
	&= \left(M(b)\jmat{x_{n-1}}{x_0}\right)^{-1}.
\end{align*}
These two cases are of course unique to the mandelbar set, but the general process should be the same for all fractals; find an equation for the series $d_k$, find some way to transform it into an already known fractal equation, and then compute $a$ as the Jacobian matrix indicating the ratio between $x_0$ and the starting value for the transformed equation.

\end{document}